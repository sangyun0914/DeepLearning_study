{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1eae5b6",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Multiple Input and Multiple Output Channels\n",
    ":label:`sec_channels`\n",
    "\n",
    "## Section Summary\n",
    "\n",
    "This section describes the notion of channels in convolutional neural networks (CNNs), which are used to process multi-dimensional data such as images or sound. When the input data has multiple channels, we need to construct a convolution kernel with the same number of channels as the input data to perform cross-correlation. This allows us to perform a cross-correlation operation for each channel and then add up the results. The same applies to the output channels, and we increase the channel depth as we go deeper into the neural network to respond to different sets of features.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8148b807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:48.083587Z",
     "iopub.status.busy": "2023-02-10T05:17:48.083159Z",
     "iopub.status.idle": "2023-02-10T05:17:51.040127Z",
     "shell.execute_reply": "2023-02-10T05:17:51.038880Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79a54845",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## Multiple Input Channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36b9a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.046802Z",
     "iopub.status.busy": "2023-02-10T05:17:51.044273Z",
     "iopub.status.idle": "2023-02-10T05:17:51.054460Z",
     "shell.execute_reply": "2023-02-10T05:17:51.052510Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e919fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.059783Z",
     "iopub.status.busy": "2023-02-10T05:17:51.058154Z",
     "iopub.status.idle": "2023-02-10T05:17:51.190491Z",
     "shell.execute_reply": "2023-02-10T05:17:51.186759Z"
    },
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eba49a6d",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "## Multiple Output Channels\n",
    ":label:`subsec_multi-output-channels`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67396215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.194650Z",
     "iopub.status.busy": "2023-02-10T05:17:51.194167Z",
     "iopub.status.idle": "2023-02-10T05:17:51.199064Z",
     "shell.execute_reply": "2023-02-10T05:17:51.198238Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of K, and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26734f81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.202912Z",
     "iopub.status.busy": "2023-02-10T05:17:51.202584Z",
     "iopub.status.idle": "2023-02-10T05:17:51.214470Z",
     "shell.execute_reply": "2023-02-10T05:17:51.210949Z"
    },
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058691bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.221682Z",
     "iopub.status.busy": "2023-02-10T05:17:51.217975Z",
     "iopub.status.idle": "2023-02-10T05:17:51.229609Z",
     "shell.execute_reply": "2023-02-10T05:17:51.228742Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104ebc71",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## $1\\times 1$ Convolutional Layer\n",
    ":label:`subsec_1x1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c5f041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.235408Z",
     "iopub.status.busy": "2023-02-10T05:17:51.233737Z",
     "iopub.status.idle": "2023-02-10T05:17:51.242656Z",
     "shell.execute_reply": "2023-02-10T05:17:51.240592Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a737b9f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-10T05:17:51.246902Z",
     "iopub.status.busy": "2023-02-10T05:17:51.246245Z",
     "iopub.status.idle": "2023-02-10T05:17:51.260044Z",
     "shell.execute_reply": "2023-02-10T05:17:51.259173Z"
    },
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
